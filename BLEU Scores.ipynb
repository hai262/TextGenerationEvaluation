{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "531a9c73-7556-4b1c-adcc-393c5690170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting BLEUScores.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile BLEUScores.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# ----------------------------\n",
    "# Monkey Patch for Fraction Error (Python 3.11+)\n",
    "import fractions\n",
    "import nltk.translate.bleu_score as bleu\n",
    "class PatchedFraction(fractions.Fraction):\n",
    "    def __new__(cls, numerator, denominator, _normalize=True):\n",
    "        return super().__new__(cls, numerator, denominator)\n",
    "bleu.Fraction = PatchedFraction\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# ----------------------------\n",
    "# Page Configuration\n",
    "st.set_page_config(page_title=\"Text Generation Evaluation with BLEU Scores\", layout=\"wide\")\n",
    "\n",
    "# ----------------------------\n",
    "# Custom CSS for an Attractive, Professional Look\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .stApp {\n",
    "        background-color: #f9f9f9;\n",
    "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    }\n",
    "    .main-header {\n",
    "        font-size: 2.8em;\n",
    "        font-weight: 600;\n",
    "        color: #2c3e50;\n",
    "        text-align: center;\n",
    "        margin-bottom: 10px;\n",
    "    }\n",
    "    .main-header-custom {\n",
    "        font-size: 3.0em;\n",
    "        font-weight: 600;\n",
    "        color: #FF6347; /* Tomato */\n",
    "        \n",
    "        text-align: justify;\n",
    "        margin: 0 20px;\n",
    "    }\n",
    "    .description-custom {\n",
    "        font-size: 1.8em;\n",
    "        color: #ccc623; /* DodgerBlue */\n",
    "        text-align: justify;\n",
    "        margin: 0 20px;\n",
    "    }\n",
    "    .sub-header {\n",
    "        font-size: 1.6em;\n",
    "        color: #34495e;\n",
    "        margin-top: 20px;\n",
    "        margin-bottom: 10px;\n",
    "    }\n",
    "    .section-header {\n",
    "        font-size: 1.2em;\n",
    "        color: #2c3e50;\n",
    "        margin-bottom: 5px;\n",
    "    }\n",
    "    .small-text {\n",
    "        font-size: 0.9em;\n",
    "        color: #7f8c8d;\n",
    "    }\n",
    "    .sidebar-section {\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Cover Page: Show Only if No Reference Text Provided\n",
    "if not st.sidebar.text_area(\"Paste your reference text here\", height=10).strip():\n",
    "    cover_html = f\"\"\"\n",
    "    <div style=\"position: relative; text-align: center; color: white;\">\n",
    "      <img src=\"https://cfcdn.decopy.ai/products/ai-humanizer.jpg\" alt=\"Cover Image\" style=\"width: 100%; opacity: 0.8;\">\n",
    "      <div style=\"position: absolute; top: 30%; left: 50%; transform: translate(-50%, -30%); width: 90%;\">\n",
    "        <div class=\"main-header-custom\">Text Generation Evaluation Using BLEU Scores</div>\n",
    "        <div class=\"description-custom\">\n",
    "          Evaluate the quality of AI-generated text using BLEU scores by comparing it with a reference text.\n",
    "          Adjust parameters and explore advanced grid search options to fine-tune your model.\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    st.markdown(cover_html, unsafe_allow_html=True)\n",
    "    st.stop()\n",
    "\n",
    "# ----------------------------\n",
    "# Sidebar: Organized into Clear Sections\n",
    "with st.sidebar:\n",
    "    st.header(\"Input & Settings\")\n",
    "    \n",
    "    # --- Reference Text Section ---\n",
    "    with st.expander(\"Reference Text\", expanded=True):\n",
    "        ref_input_method = st.radio(\"Select Input Method\", (\"Upload File\", \"Paste Text\"))\n",
    "        if ref_input_method == \"Upload File\":\n",
    "            uploaded_file = st.file_uploader(\"Upload .txt file\", type=[\"txt\"])\n",
    "            if uploaded_file:\n",
    "                reference_text = uploaded_file.read().decode(\"utf-8\")\n",
    "            else:\n",
    "                reference_text = \"\"\n",
    "        else:\n",
    "            reference_text = st.text_area(\"Paste Reference Text\", height=150)\n",
    "    \n",
    "    # --- Markov Chain Settings ---\n",
    "    with st.expander(\"Markov Chain Settings\", expanded=True):\n",
    "        st.markdown(\"Adjust the parameters for the text generation model:\")\n",
    "        ngram_order = st.slider(\"n-gram Order\", min_value=2, max_value=4, value=2, step=1)\n",
    "        num_words_to_generate = st.slider(\"Words to Generate\", 20, 200, 50, step=10)\n",
    "        num_samples = st.slider(\"Number of Samples\", 3, 20, 5, step=1)\n",
    "    \n",
    "    # --- Smoothing Method Selection ---\n",
    "    with st.expander(\"Smoothing Method\", expanded=True):\n",
    "        smoothing_method = st.selectbox(\"Select Smoothing Method\", \n",
    "                                        options=[\"Method 1\", \"Method 2\", \"Method 3\", \n",
    "                                                 \"Method 4\", \"Method 5\", \"Method 6\", \"Method 7\"],\n",
    "                                        index=0)\n",
    "    \n",
    "    # --- Advanced Grid Search Settings ---\n",
    "    with st.expander(\"Advanced Grid Search Settings\", expanded=False):\n",
    "        enable_grid_search = st.checkbox(\"Enable Grid Search\", value=False)\n",
    "        if enable_grid_search:\n",
    "            grid_ngram = st.multiselect(\"n-gram Orders\", options=[2, 3, 4], default=[2, 3, 4])\n",
    "            grid_words = st.multiselect(\"Words to Generate\", options=[20, 50, 100], default=[20, 50, 100])\n",
    "            grid_samples = st.number_input(\"Samples for Grid Search\", min_value=1, max_value=20, value=3, step=1)\n",
    "            grid_smoothing = st.multiselect(\"Smoothing Methods\", \n",
    "                                            options=[\"Method 1\", \"Method 2\", \"Method 3\", \n",
    "                                                     \"Method 4\", \"Method 5\", \"Method 6\", \"Method 7\"],\n",
    "                                            default=[\"Method 1\"])\n",
    "        compare_all = st.checkbox(\"Compare All Smoothing Methods\", value=False)\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "def build_ngram_model(text, n):\n",
    "    \"\"\"Build an n-gram Markov Chain model from text.\"\"\"\n",
    "    text_clean = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    words = text_clean.lower().split()\n",
    "    model = {}\n",
    "    for i in range(len(words) - n):\n",
    "        key = tuple(words[i:i+n])\n",
    "        next_word = words[i+n]\n",
    "        model.setdefault(key, []).append(next_word)\n",
    "    return model\n",
    "\n",
    "def generate_text_from_model(model, start_tuple, num_words):\n",
    "    \"\"\"Generate text using the Markov Chain model.\"\"\"\n",
    "    current_tuple = start_tuple\n",
    "    output = list(current_tuple)\n",
    "    for _ in range(num_words - len(current_tuple)):\n",
    "        next_words = model.get(current_tuple, None)\n",
    "        if not next_words:\n",
    "            break\n",
    "        next_word = random.choice(next_words)\n",
    "        output.append(next_word)\n",
    "        current_tuple = tuple(output[-len(current_tuple):])\n",
    "    return \" \".join(output)\n",
    "\n",
    "def calculate_bleu(reference, generated_texts, smoothing_method_str=\"method1\"):\n",
    "    \"\"\"Calculate BLEU scores for generated texts using a specified smoothing method.\"\"\"\n",
    "    sf = SmoothingFunction()\n",
    "    smoothing = getattr(sf, smoothing_method_str)\n",
    "    reference_tokens = [nltk.word_tokenize(reference.lower())]\n",
    "    scores = []\n",
    "    for text in generated_texts:\n",
    "        candidate_tokens = nltk.word_tokenize(text.lower())\n",
    "        score = sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def compare_smoothing_methods(reference, generated_texts):\n",
    "    \"\"\"Compare average BLEU scores for all smoothing methods.\"\"\"\n",
    "    methods = [\"method1\", \"method2\", \"method3\", \"method4\", \"method5\", \"method6\", \"method7\"]\n",
    "    avg_scores = {}\n",
    "    for m in methods:\n",
    "        scores = calculate_bleu(reference, generated_texts, smoothing_method_str=m)\n",
    "        avg_scores[m] = np.mean(scores)\n",
    "    return avg_scores\n",
    "\n",
    "def run_grid_search(reference, grid_ngram, grid_words, grid_samples, grid_smoothing):\n",
    "    \"\"\"Perform grid search over model parameters and smoothing methods.\"\"\"\n",
    "    results = []\n",
    "    for n in grid_ngram:\n",
    "        model = build_ngram_model(reference, n)\n",
    "        unique_keys = list(model.keys())\n",
    "        if not unique_keys:\n",
    "            continue\n",
    "        for w in grid_words:\n",
    "            for s_method in grid_smoothing:\n",
    "                generated_texts = [generate_text_from_model(model, random.choice(unique_keys), w)\n",
    "                                   for _ in range(grid_samples)]\n",
    "                method_key = s_method.lower().replace(\" \", \"\")\n",
    "                scores = calculate_bleu(reference, generated_texts, smoothing_method_str=method_key)\n",
    "                avg_bleu = np.mean(scores)\n",
    "                results.append({\n",
    "                    \"n-gram Order\": n,\n",
    "                    \"Words Generated\": w,\n",
    "                    \"Smoothing Method\": s_method,\n",
    "                    \"Average BLEU\": avg_bleu\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ----------------------------\n",
    "# Main Application Logic\n",
    "if reference_text:\n",
    "    # Build the main Markov model using provided n-gram order\n",
    "    model_main = build_ngram_model(reference_text, ngram_order)\n",
    "    unique_keys_main = list(model_main.keys())\n",
    "    \n",
    "    if not unique_keys_main:\n",
    "        st.error(\"Reference text is too short for the chosen n-gram order. Please use a longer text.\")\n",
    "    else:\n",
    "        # Generate samples and calculate BLEU scores for the main run\n",
    "        machine_texts = [generate_text_from_model(model_main, random.choice(unique_keys_main), num_words_to_generate)\n",
    "                         for _ in range(num_samples)]\n",
    "        selected_method = smoothing_method.lower().replace(\" \", \"\")\n",
    "        bleu_scores = calculate_bleu(reference_text, machine_texts, smoothing_method_str=selected_method)\n",
    "        \n",
    "        # Organize main output into tabs\n",
    "        main_tabs = st.tabs([\"Overview\", \"Generated Samples\", \"Visualizations\", \"Parameter Tuning\", \"Download Results\"])\n",
    "        \n",
    "        # --- Tab 1: Overview ---\n",
    "        with main_tabs[0]:\n",
    "            st.markdown(\"<div class='sub-header'>Overview & Settings</div>\", unsafe_allow_html=True)\n",
    "            st.text_area(\"Reference Text Preview (first 1000 characters)\", reference_text[:1000], height=180)\n",
    "            st.markdown(f\"**Markov Chain Settings:** n-gram order = {ngram_order}, words = {num_words_to_generate}, samples = {num_samples}\")\n",
    "            st.markdown(f\"**Smoothing Method:** {smoothing_method}\")\n",
    "        \n",
    "        # --- Tab 2: Generated Samples ---\n",
    "        with main_tabs[1]:\n",
    "            st.markdown(\"<div class='sub-header'>Generated Samples & BLEU Scores</div>\", unsafe_allow_html=True)\n",
    "            for i, text in enumerate(machine_texts):\n",
    "                st.markdown(f\"**Sample {i+1} (BLEU Score: {bleu_scores[i]:.4f})**\")\n",
    "                st.write(text)\n",
    "        \n",
    "        # --- Tab 3: Visualizations ---\n",
    "        with main_tabs[2]:\n",
    "            st.markdown(\"<div class='sub-header'>BLEU Score Visualizations</div>\", unsafe_allow_html=True)\n",
    "            # Histogram\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            sns.histplot(bleu_scores, bins=10, kde=True, color=\"blue\", alpha=0.7)\n",
    "            plt.axvline(np.mean(bleu_scores), color='red', linestyle='dashed', label=f'Avg: {np.mean(bleu_scores):.4f}')\n",
    "            plt.title(\"BLEU Score Distribution\")\n",
    "            plt.xlabel(\"BLEU Score\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            st.pyplot(fig)\n",
    "            # Scatter Plot\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            plt.scatter(range(1, len(bleu_scores)+1), bleu_scores, color='purple', s=50)\n",
    "            plt.axhline(np.mean(bleu_scores), color='red', linestyle='dashed', label=f'Avg: {np.mean(bleu_scores):.4f}')\n",
    "            plt.title(\"BLEU Scores per Sample\")\n",
    "            plt.xlabel(\"Sample Number\")\n",
    "            plt.ylabel(\"BLEU Score\")\n",
    "            plt.legend()\n",
    "            st.pyplot(fig)\n",
    "            # Boxplot\n",
    "            fig, ax = plt.subplots(figsize=(6, 4))\n",
    "            sns.boxplot(x=bleu_scores, color=\"green\")\n",
    "            plt.title(\"Boxplot of BLEU Scores\")\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        # --- Tab 4: Parameter Tuning ---\n",
    "        with main_tabs[3]:\n",
    "            st.markdown(\"<div class='sub-header'>Parameter Tuning & Smoothing Comparison</div>\", unsafe_allow_html=True)\n",
    "            if compare_all:\n",
    "                avg_scores = compare_smoothing_methods(reference_text, machine_texts)\n",
    "                df_compare = pd.DataFrame(list(avg_scores.items()), columns=[\"Smoothing Method\", \"Avg BLEU Score\"])\n",
    "                st.dataframe(df_compare)\n",
    "                st.markdown(\"**Bar Chart: Smoothing Method Comparison**\")\n",
    "                fig, ax = plt.subplots(figsize=(8,5))\n",
    "                sns.barplot(data=df_compare, x=\"Smoothing Method\", y=\"Avg BLEU Score\", palette=\"viridis\")\n",
    "                plt.title(\"Average BLEU Score by Smoothing Method\")\n",
    "                plt.ylabel(\"Avg BLEU Score\")\n",
    "                st.pyplot(fig)\n",
    "            else:\n",
    "                st.info(\"Enable 'Compare All Smoothing Methods' in the sidebar to view comparisons.\")\n",
    "        \n",
    "        # --- Tab 5: Download Results ---\n",
    "        with main_tabs[4]:\n",
    "            st.markdown(\"<div class='sub-header'>Download BLEU Scores</div>\", unsafe_allow_html=True)\n",
    "            df_bleu = pd.DataFrame({\n",
    "                \"Sample Number\": range(1, num_samples + 1),\n",
    "                \"BLEU Score\": bleu_scores\n",
    "            })\n",
    "            st.dataframe(df_bleu)\n",
    "            csv_bleu = df_bleu.to_csv(index=False)\n",
    "            st.download_button(\"Download BLEU Scores CSV\", data=csv_bleu, file_name=\"bleu_scores.csv\", mime=\"text/csv\")\n",
    "        \n",
    "        # --- Optional Grid Search Tab ---\n",
    "        if enable_grid_search:\n",
    "            grid_tabs = st.tabs([\"Grid Search Results\", \"Grid Search Visualizations\"])\n",
    "            with grid_tabs[0]:\n",
    "                st.markdown(\"<div class='sub-header'>Grid Search Results</div>\", unsafe_allow_html=True)\n",
    "                df_grid = run_grid_search(reference_text, grid_ngram, grid_words, grid_samples, grid_smoothing)\n",
    "                if df_grid.empty:\n",
    "                    st.error(\"Grid search did not return any results. Adjust grid parameters or use a longer reference text.\")\n",
    "                else:\n",
    "                    st.dataframe(df_grid)\n",
    "            with grid_tabs[1]:\n",
    "                st.markdown(\"<div class='sub-header'>Grid Search Heatmaps</div>\", unsafe_allow_html=True)\n",
    "                if not df_grid.empty:\n",
    "                    for s_method in grid_smoothing:\n",
    "                        df_subset = df_grid[df_grid[\"Smoothing Method\"] == s_method]\n",
    "                        if df_subset.empty:\n",
    "                            continue\n",
    "                        pivot = df_subset.pivot(index=\"n-gram Order\", columns=\"Words Generated\", values=\"Average BLEU\")\n",
    "                        st.markdown(f\"**Smoothing Method: {s_method}**\")\n",
    "                        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "                        sns.heatmap(pivot, annot=True, cmap=\"YlGnBu\", fmt=\".4f\")\n",
    "                        plt.title(f\"Heatmap ({s_method})\")\n",
    "                        st.pyplot(fig)\n",
    "else:\n",
    "    st.info(\"⚠️ Please upload or paste a reference text to begin analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fef19-7c1b-426a-a9cf-86a752a2b3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
